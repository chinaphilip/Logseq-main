- [总结当下可用的大模型LLMs - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/611403556)
- | Model | 作者 | Size | 类型 | 开源？ |
  | LLaMa | Meta AI | 7B-65B | Decoder | open |
  | OPT | Meta AI | 125M-175B | Decoder | open |
  | T5 | Google | 220M-11B | Encoder-Decoder | open |
  | mT5 | Google | 235M-13B | Encoder-Decoder | open |
  | UL2 | Google | 20B | Encoder-Decoder | open |
  | PaLM | Google | 540B | Decoder | no |
  | LaMDA | Google | 2B-137B | Decoder | no |
  | FLAN-T5 | Google | 同T5 | Encoder-Decoder | open |
  | FLAN-UL2 | Google | 同U2 | Encoder-Decoder | open |
  | FLAN-PaLM | Google | 同PaLM | Decoder | no |
  | FLAN | Google | 同LaMDA | Decoder | no |
  | BLOOM | BigScience | 176B | Decoder | open |
  | T0 | BigScience | 3B | Decoder | open |
  | BLOOMZ | BigScience | 同BLOOM | Decoder | open |
  | mT0 | BigScience | 同T0 | Decoder | open |
  | GPT-Neo | EleutherAI | 125M-2.7B | Decoder | open |
  | GPT-NeoX | EleutherAI | 20B | Decoder | open |
  | GPT3 | OpenAI | 175B (davinci) | Decoder | no |
  | GPT4 | OpenAI | unknown | OpenAI | no |
  | InstructGPT | OpenAI | 1.3B | Decoder | no |
  | Alpaca | Stanford | 同LLaMa | Decoder | open |
- [nomic-ai/gpt4all: gpt4all: a chatbot trained on a massive collection of clean assistant data including code, stories and dialogue (github.com)](https://github.com/nomic-ai/gpt4all)
-