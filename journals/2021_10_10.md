- [[Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks；]]
- Bert模型已经在NLP各大任务中都展现出了强者的姿态。在语义相似度计算（semantic textual similarity）任务上也不例外，但是，由于bert模型规定，在计算语义相似度时，需要将两个句子同时进入模型，进行信息交互，这造成大量的计算开销。例如，有10000个句子，我们想要找出最相似的句子对，需要计算（10000*9999/2）次，需要大约65个小时。Bert模型的构造使得它既不适合语义相似度搜索，也不适合非监督任务，比如聚类。
- sentence-bert可以用来做剧烈
# 当BERT遇上知识图谱
- 上篇博客理了一下一些知识表示学习模型，那今天我们来看目前最流行的BERT模型加上外部知识这个buff后到底会有怎么样的发展。其实这个思路在之前就有出现过比较有意思且高效的工作，像百度的ERNIE和ERNIE2.0 以及清华的ERNIE，这些工作的介绍可以参考站在BERT肩膀上的NLP新秀们（PART I）。