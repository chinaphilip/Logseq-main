- [[2019-Improving short text classification through global augmentation methods ]]通过全局数据增强提升短文本分类
- [[BaKGraSTeC: A Background Knowledge Graph Based Method for Short Text classification]]
- [[A Short Text Classification Approach with Event Detection and Conceptual Information]]
- [[A Survey on Knowledge Graph-Based Recommender Systems]]
- [[Combining Knowledge with Deep Convolutional Neural Networks for Short Text Classification]]这篇是用的比较浅的模型做的文本分类（IJCAI-2017）
-
-
  ****
- 考虑query、key、value都相等的情况，也就是self-attention。
- transformer中计算注意力打分的函数用的是缩放点积模型也称为scaled dot product
-
- self-attention在transformer中第一次被提出
-
-